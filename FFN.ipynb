{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "569d7797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fcbe8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self,weights,bias):\n",
    "        \"\"\"\n",
    "        inputs : a vector of inputs\n",
    "        weights : a vector of weights\n",
    "        eta : learning rate \n",
    "        output : the provided output\n",
    "        \"\"\"\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        self.n = len(self.weights)\n",
    "    \n",
    "    def activation_function(self, x):\n",
    "        # sigmoid function\n",
    "        return 1/(1+math.exp(-x))\n",
    "    \n",
    "    def Hard_activation_function(self, x):\n",
    "        return 1 if x > 0 else 0\n",
    "    \n",
    "    def predict(self,inputs):\n",
    "        if len(self.weights)!= self.n:\n",
    "            raise ValueError(\"Weights don't match inputs\")\n",
    "        x = sum([self.weights[i]*inputs[i] for i in range(self.n)])-self.bias\n",
    "        return self.Hard_activation_function(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9723b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronLayer:\n",
    "    def __init__(self, id, num_perceptrons,weights=None,biases=None):\n",
    "        \"\"\"\n",
    "        num_perceptrons : number of perceptrons in the layer\n",
    "        id : layer id i.e it's number in the network\n",
    "        weights : matrix of weights for the perceptron where each row corresponds to a perceptron\n",
    "        biases : vector of biases for each perceptron\n",
    "        \"\"\"\n",
    "        self.layer_id = id\n",
    "        self.num_perceptrons = num_perceptrons\n",
    "        self.inputs = []\n",
    "        if weights is None:\n",
    "            weights = [[0.5 for _ in range(num_perceptrons)] for _ in range(num_perceptrons)]\n",
    "        if biases is None:\n",
    "            biases = [0.0 for _ in range(num_perceptrons)]\n",
    "        if len(weights) != num_perceptrons or len(biases) != num_perceptrons:\n",
    "            raise ValueError(\"Weights or biases dimensions do not match number of perceptrons\")\n",
    "        self.layer = [Perceptron(weights[i], biases[i]) for i in range(num_perceptrons)] \n",
    "        self.output = [0.0 for _ in range(num_perceptrons)]\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        output = []\n",
    "        for neuron in self.layer:\n",
    "            output.append(neuron.predict(inputs))\n",
    "        self.output = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6694629a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Layer = PerceptronLayer(1,3)\n",
    "print(Layer.predict([0,0,0])) \n",
    "Layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e39ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNeuralNetwork:\n",
    "    def __init__(self, inputs,outputs,num_Hidden_layers,neurons_per_hidden_layer):\n",
    "        \"\"\"\n",
    "        inputs : number of inputs\n",
    "        outputs : number of outputs\n",
    "        num_Hidden_layers : number of hidden layers\n",
    "        neurons_per_hidden_layer : list of numbers containing number of neurons per hidden layer\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.num_Hidden_layers = num_Hidden_layers\n",
    "        self.neurons_per_hidden_layer = neurons_per_hidden_layer\n",
    "        self.mlp = []\n",
    "        # create input layer    \n",
    "        input_layer = PerceptronLayer(0, neurons_per_hidden_layer[0],\n",
    "                                      weights=[[0.5 for _ in range(inputs)] for _ in range(neurons_per_hidden_layer[0])],\n",
    "                                      biases=[0.0 for _ in range(neurons_per_hidden_layer[0])])\n",
    "        self.mlp.append(input_layer)\n",
    "        # create hidden layers\n",
    "        for i in range(1, num_Hidden_layers):\n",
    "            hidden_layer = PerceptronLayer(i, neurons_per_hidden_layer[i],\n",
    "                                           weights=[[0.5 for _ in range(neurons_per_hidden_layer[i-1])] for _ in range(neurons_per_hidden_layer[i])],\n",
    "                                           biases=[0.0 for _ in range(neurons_per_hidden_layer[i])])\n",
    "            self.mlp.append(hidden_layer)\n",
    "        # create output layer\n",
    "        output_layer = PerceptronLayer(num_Hidden_layers, outputs,\n",
    "                                       weights=[[0.5 for _ in range(neurons_per_hidden_layer[-1])] for _ in range(outputs)],\n",
    "                                       biases=[0.0 for _ in range(outputs)])\n",
    "        self.mlp.append(output_layer)\n",
    "        \n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        return self.mlp.predict(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
