{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "569d7797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fcbe8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self,weights,bias):\n",
    "        \"\"\"\n",
    "        inputs : a vector of inputs\n",
    "        weights : a vector of weights\n",
    "        eta : learning rate \n",
    "        output : the provided output\n",
    "        \"\"\"\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        self.n = len(self.weights)\n",
    "    \n",
    "    def activation_function(self, x):\n",
    "        # sigmoid function\n",
    "        return 1/(1+math.exp(-x))\n",
    "    \n",
    "    def Hard_activation_function(self, x):\n",
    "        return 1 if x > 0 else 0\n",
    "    \n",
    "    def predict(self,inputs):\n",
    "        if len(self.weights)!= self.n:\n",
    "            raise ValueError(\"Weights don't match inputs\")\n",
    "        x = sum([self.weights[i]*inputs[i] for i in range(self.n)])-self.bias\n",
    "        return self.Hard_activation_function(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9723b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronLayer:\n",
    "    def __init__(self, id, num_perceptrons,weights=None,biases=None):\n",
    "        \"\"\"\n",
    "        num_perceptrons : number of perceptrons in the layer\n",
    "        id : layer id i.e it's number in the network\n",
    "        weights : matrix of weights for the perceptron where each row corresponds to a perceptron\n",
    "        biases : vector of biases for each perceptron\n",
    "        \"\"\"\n",
    "        self.layer_id = id\n",
    "        self.num_perceptrons = num_perceptrons\n",
    "        if weights is None:\n",
    "            weights = [[0.5 for _ in range(num_perceptrons)] for _ in range(num_perceptrons)]\n",
    "        if biases is None:\n",
    "            biases = [0.0 for _ in range(num_perceptrons)]\n",
    "        if len(weights) != num_perceptrons or len(biases) != num_perceptrons:\n",
    "            raise ValueError(\"Weights or biases dimensions do not match number of perceptrons\")\n",
    "        self.layer = [Perceptron(weights[i], biases[i]) for i in range(num_perceptrons)] \n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        output = inputs\n",
    "        for neuron in self.layer:\n",
    "            output = [neuron.predict(output)]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6694629a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m Layer = PerceptronLayer(\u001b[32m1\u001b[39m,\u001b[32m3\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mLayer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m) \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mPerceptronLayer.predict\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m     20\u001b[39m output = inputs\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m neuron \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layer:\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     output = [\u001b[43mneuron\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mPerceptron.predict\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.weights)!= \u001b[38;5;28mself\u001b[39m.n:\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mWeights don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt match inputs\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m x = \u001b[38;5;28msum\u001b[39m([\u001b[38;5;28mself\u001b[39m.weights[i]*\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.n)])-\u001b[38;5;28mself\u001b[39m.bias\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.Hard_activation_function(x)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "Layer = PerceptronLayer(1,3)\n",
    "print(Layer.predict([1,0,1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e39ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNeuralNetwork:\n",
    "    def __init__(self, inputs,outputs,num_Hidden_layers,neurons_per_hidden_layer):\n",
    "        \"\"\"\n",
    "        inputs : number of inputs\n",
    "        outputs : number of outputs\n",
    "        num_Hidden_layers : number of hidden layers\n",
    "        neurons_per_hidden_layer : list of numbers containing number of neurons per hidden layer\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.num_Hidden_layers = num_Hidden_layers\n",
    "        self.neurons_per_hidden_layer = neurons_per_hidden_layer\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        return self.mlp.predict(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
