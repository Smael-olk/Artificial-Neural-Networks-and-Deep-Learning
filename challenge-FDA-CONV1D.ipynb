{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Library & Data Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from skfda.representation.basis import BSpline\n",
        "from skfda.representation import FDataGrid\n",
        "from skfda.preprocessing.dim_reduction import FPCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skfda.representation.basis import BSpline\n",
        "from skfda.representation.grid import FDataGrid\n",
        "from tqdm import tqdm # Useful for tracking progress\n",
        "from skfda.representation.basis import Basis\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- ASSUMED LOADED DATA ---\n",
        "# Replace with your actual loading code:\n",
        "df_train = pd.read_csv(\"../data/pirate_pain_train.csv\")\n",
        "df_labels = pd.read_csv(\"../data/pirate_pain_train_labels.csv\")\n",
        "df_test = pd.read_csv(\"../data/pirate_pain_test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming df_train is the long-format DataFrame\n",
        "scalar_cols = ['sample_index', 'pain_survey_1', 'pain_survey_2', 'pain_survey_3', 'pain_survey_4', \n",
        "               'n_legs', 'n_hands', 'n_eyes']\n",
        "\n",
        "# Extract the unique rows for each pirate (one row per sample_index)\n",
        "df_scalars = df_train[scalar_cols].drop_duplicates(subset=['sample_index']).sort_values(by='sample_index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Define the mapping for count-based strings\n",
        "count_mapping = {\n",
        "    'one': 1,\n",
        "    'two': 2,\n",
        "    'three': 3,\n",
        "    'four': 4,\n",
        "    # Add any other observed string values here\n",
        "}\n",
        "\n",
        "# 2. Apply mapping to the relevant columns\n",
        "for col in ['n_legs', 'n_hands', 'n_eyes']:\n",
        "    # Replace the string values with their corresponding integer. \n",
        "    # Use .fillna() to handle any unknown or missing strings after the mapping.\n",
        "    df_scalars[col] = df_scalars[col].map(count_mapping).fillna(0).astype(int) \n",
        "    # NOTE: Filling with 0 assumes an unknown part count means 0, adjust as needed.\n",
        "\n",
        "# 3. Handle Pain Surveys (Check if they need conversion)\n",
        "# pain_survey_X columns appear to be integers (2, 0, 2, 1) in your sample, \n",
        "# but if they were strings (e.g., 'low', 'high'), they would also need mapping/OHE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(661, 7)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Drop the index column before scaling\n",
        "X_scalars_raw = df_scalars.drop(columns=['sample_index']).values\n",
        "\n",
        "# Apply Standard Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scalars_scaled = scaler.fit_transform(X_scalars_raw)\n",
        "X_scalars_scaled.shape  # Should be (num_samples, num_scalar_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3D Functional Array X_functional_3D created with shape: (661, 160, 31)\n"
          ]
        }
      ],
      "source": [
        "from skfda.representation.grid import FDataGrid\n",
        "\n",
        "# --- ASSUMPTIONS BASED ON YOUR DATA STRUCTURE ---\n",
        "# df_train has shape (160 * 661, 40)\n",
        "# 'sample_index' identifies the 661 pirates.\n",
        "# 'time' has 160 unique time steps.\n",
        "functional_cols = [col for col in df_train.columns if col.startswith('joint_')]\n",
        "\n",
        "# 1. Sort the DataFrame\n",
        "# Ensure the data is sorted by pirate and then by time step. \n",
        "# This is crucial for the reshape operation to work correctly.\n",
        "df_train_sorted = df_train.sort_values(by=['sample_index', 'time'])\n",
        "\n",
        "# 2. Extract the functional domain (time vector)\n",
        "t = df_train_sorted['time'].unique()\n",
        "n_time_points = len(t) # Should be 160\n",
        "\n",
        "# 3. Extract the functional values and reshape\n",
        "X_functional = df_train_sorted[functional_cols].values\n",
        "# X_functional shape is (105760, 31) where 105760 = 160 * 661\n",
        "\n",
        "# Reshape to a 3D array: (n_pirates, n_time_points, n_functions)\n",
        "n_pirates = df_train['sample_index'].nunique() # Should be 661\n",
        "n_functions = len(functional_cols)           # Should be 31\n",
        "\n",
        "X_functional_3D = X_functional.reshape(n_pirates, n_time_points, n_functions)\n",
        "\n",
        "print(f\"3D Functional Array X_functional_3D created with shape: {X_functional_3D.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Functional Data Object fd_train is now defined.\n",
            "   Samples (Pirates): 661\n",
            "   Features (Joints/Codomain): 31\n"
          ]
        }
      ],
      "source": [
        "# Create the Functional Data Object\n",
        "fd_train = FDataGrid(\n",
        "    data_matrix=X_functional_3D,\n",
        "    grid_points=t\n",
        ")\n",
        "\n",
        "# Corrected print statements\n",
        "print(f\"\\n✅ Functional Data Object fd_train is now defined.\")\n",
        "print(f\"   Samples (Pirates): {fd_train.n_samples}\") # 661 (Number of functions/pirates)\n",
        "print(f\"   Features (Joints/Codomain): {fd_train.dim_codomain}\") # 31 (Number of measurements per time point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split fd_train into 31 separate FDataGrid objects.\n"
          ]
        }
      ],
      "source": [
        "# Assuming fd_train is defined (shape 661, 160, 31)\n",
        "list_of_fd_grids = []\n",
        "\n",
        "# Iterate through each of the 31 joint functions (codomain dimensions)\n",
        "for i in range(fd_train.dim_codomain):\n",
        "    # Select the i-th function (i.e., joint_i)\n",
        "    fd_joint_i = fd_train.coordinates[i]\n",
        "    list_of_fd_grids.append(fd_joint_i)\n",
        "    \n",
        "print(f\"Split fd_train into {len(list_of_fd_grids)} separate FDataGrid objects.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Leon\\AppData\\Local\\Temp\\ipykernel_5556\\3319661513.py:9: DeprecationWarning: The BSpline class is deprecated. Use BSplineBasis instead.\n",
            "  basis = BSpline(n_basis=n_basis)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elbow plot saved to 'fpca_elbow_plot.png'\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skfda.preprocessing.dim_reduction import FPCA \n",
        "from skfda.representation.basis import BSpline\n",
        "\n",
        "# --- 1. Setup Basis and Select Example Joint ---\n",
        "# Use the same n_basis as your main pipeline\n",
        "n_basis = 20\n",
        "basis = BSpline(n_basis=n_basis)\n",
        "\n",
        "# Select one joint to analyze (e.g., the first one)\n",
        "# list_of_fd_grids comes from your notebook\n",
        "fd_joint_example = list_of_fd_grids[0] \n",
        "\n",
        "# --- 2. Fit FPCA *without* n_components ---\n",
        "# This is the key step: by not setting n_components, \n",
        "# it calculates variance for all components up to n_basis.\n",
        "fpca_analyzer = FPCA(components_basis=basis)\n",
        "fpca_analyzer.fit(fd_joint_example)\n",
        "\n",
        "# --- 3. Get Explained Variance Ratios ---\n",
        "# This holds the percentage of variance each component explains\n",
        "explained_var = fpca_analyzer.explained_variance_ratio_\n",
        "component_numbers = range(1, len(explained_var) + 1)\n",
        "\n",
        "# --- 4. Plot the Scree Plot (Elbow Method) ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(component_numbers, explained_var, 'bo-', linewidth=2, markersize=8)\n",
        "plt.title('Scree Plot for Joint 0 (Elbow Method)')\n",
        "plt.xlabel('Principal Component Number')\n",
        "plt.ylabel('Explained Variance Ratio (Individual)')\n",
        "plt.grid(True)\n",
        "plt.xticks(component_numbers) # Ensure we have integer labels for each component\n",
        "plt.savefig('fpca_elbow_plot.png')\n",
        "\n",
        "print(f\"Elbow plot saved to 'fpca_elbow_plot.png'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Leon\\AppData\\Local\\Temp\\ipykernel_5556\\257495552.py:7: DeprecationWarning: The BSpline class is deprecated. Use BSplineBasis instead.\n",
            "  basis = BSpline(n_basis=n_basis)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total FPCA Score Matrix shape: (661, 93)\n"
          ]
        }
      ],
      "source": [
        "from skfda.preprocessing.dim_reduction import FPCA \n",
        "from skfda.representation.basis import BSpline\n",
        "\n",
        "# Configuration (e.g., let's use 3 components per joint for a total of 31 * 3 = 93 features)\n",
        "n_components_per_joint = 3\n",
        "n_basis = 20\n",
        "basis = BSpline(n_basis=n_basis)\n",
        "\n",
        "all_fpc_scores = []\n",
        "fpca = FPCA(n_components=n_components_per_joint, components_basis=basis)\n",
        "\n",
        "for i, fd_joint in enumerate(list_of_fd_grids):\n",
        "    # Fit and transform the current joint's functional data\n",
        "    fpca.fit(fd_joint)\n",
        "    scores_i = fpca.transform(fd_joint)\n",
        "    all_fpc_scores.append(scores_i)\n",
        "    \n",
        "    # Optional check: print(f\"Joint {i} transformed to shape: {scores_i.shape}\")\n",
        "\n",
        "# Concatenate all scores horizontally (along the features axis)\n",
        "X_fpc_scores_concatenated = np.hstack(all_fpc_scores)\n",
        "\n",
        "print(f\"Total FPCA Score Matrix shape: {X_fpc_scores_concatenated.shape}\")\n",
        "# Expected shape: (661, 31 * 3) = (661, 93)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Combined Feature Matrix X_combined shape: (661, 100)\n"
          ]
        }
      ],
      "source": [
        "# Assuming X_scalars_scaled is available (shape: 661, 7)\n",
        "X_combined = np.hstack([X_fpc_scores_concatenated, X_scalars_scaled])\n",
        "\n",
        "print(f\"Final Combined Feature Matrix X_combined shape: {X_combined.shape}\")\n",
        "# Expected shape: (661, 93 FPCs + 7 Scalars) = (661, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Target variable y_train defined with shape: (661,)\n",
            "Number of unique classes: 3\n"
          ]
        }
      ],
      "source": [
        "# Assuming df_labels was loaded earlier:\n",
        "# df_labels = pd.read_csv(\"../data/pirate_pain_train_labels.csv\")\n",
        "\n",
        "# 1. Inspect df_labels to find the target column\n",
        "# Assuming the labels file contains 'sample_index' and the target column is 'pirate_class' \n",
        "# (You may need to adjust 'target_column_name' based on your actual file).\n",
        "TARGET_COLUMN_NAME = 'label' # Replace with the actual column name\n",
        "\n",
        "# 2. Sort the labels by 'sample_index' to align with the features\n",
        "# We must ensure the labels are in the same order as the pirates in X_functional_3D and X_scalars_scaled.\n",
        "df_labels_sorted = df_labels.sort_values(by='sample_index')\n",
        "\n",
        "# 3. Extract the target variable\n",
        "y_train = df_labels_sorted[TARGET_COLUMN_NAME].values\n",
        "\n",
        "print(f\"✅ Target variable y_train defined with shape: {y_train.shape}\")\n",
        "print(f\"Number of unique classes: {len(np.unique(y_train))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ String labels successfully mapped to integers.\n",
            "Original Classes: ['high_pain' 'low_pain' 'no_pain']\n",
            "Encoded Integers: [0 1 2]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Assuming y_train is the array of string labels (e.g., ['no_pain', 'low_pain', 'no_pain', ...])\n",
        "\n",
        "# 1. Initialize the LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# 2. Fit the encoder to all unique labels and transform y_train\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "# Update y_train to the new encoded version\n",
        "y_train = y_train_encoded\n",
        "\n",
        "# Print the mapping for verification\n",
        "print(\"✅ String labels successfully mapped to integers.\")\n",
        "print(f\"Original Classes: {label_encoder.classes_}\")\n",
        "print(f\"Encoded Integers: {np.unique(y_train)}\")\n",
        "\n",
        "# Re-determine the number of classes using the encoded labels\n",
        "num_classes = len(np.unique(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Data split completed (Functional Data Only).\n",
            "Functional Training shape: (528, 160, 31)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Determine the number of classes and check if it's binary or multi-class\n",
        "num_classes = len(np.unique(y_train))\n",
        "is_binary = (num_classes == 2)\n",
        "\n",
        "# Split the functional features and labels only\n",
        "X_func_train, X_func_val, y_train_split, y_val = train_test_split(\n",
        "    X_functional_3D,\n",
        "    y_train,\n",
        "    test_size=0.2, \n",
        "    random_state=42, \n",
        "    stratify=y_train \n",
        ")\n",
        "\n",
        "# Prepare labels (One-Hot Encoding for multi-class)\n",
        "if not is_binary:\n",
        "    y_train_proc = to_categorical(y_train_split, num_classes=num_classes)\n",
        "    y_val_proc = to_categorical(y_val, num_classes=num_classes)\n",
        "else:\n",
        "    y_train_proc = y_train_split\n",
        "    y_val_proc = y_val\n",
        "\n",
        "print(\"✅ Data split completed (Functional Data Only).\")\n",
        "print(f\"Functional Training shape: {X_func_train.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculated Class Weights: {np.int64(2): 0.43118069145466403, np.int64(1): 2.3439716312056738, np.int64(0): 3.9345238095238093}\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Assuming y_train is your final encoded integer array (0, 1, 2, ...)\n",
        "class_counts = Counter(y_train)\n",
        "total_samples = len(y_train)\n",
        "num_classes = len(class_counts)\n",
        "\n",
        "# Calculate weights dictionary\n",
        "class_weights = {}\n",
        "for cls, count in class_counts.items():\n",
        "    class_weights[cls] = total_samples / (count * num_classes)\n",
        "    \n",
        "print(f\"Calculated Class Weights: {class_weights}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CONV1D Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Random Search CV (Conv1D) with 50 trials and 5 folds...\n",
            "\n",
            "--- Trial 1/50. Params: {'conv_filters': 128, 'kernel_size': 9, 'dropout_rate': 0.5, 'l2_penalty': 1e-05, 'batch_size': 16} ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fold 1 F1 Score: 0.6905\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fold 2 F1 Score: 0.4015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fold 3 F1 Score: 0.3339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fold 4 F1 Score: 0.5050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fold 5 F1 Score: 0.3164\n",
            "  --> Average F1 Score: 0.4495\n",
            "\n",
            "--- Trial 2/50. Params: {'conv_filters': 128, 'kernel_size': 3, 'dropout_rate': 0.4, 'l2_penalty': 1e-05, 'batch_size': 32} ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from collections import Counter # Needed for class weight calculation\n",
        "\n",
        "# --- 0. PRE-CALCULATIONS (For Class Weights) ---\n",
        "# Assuming y_train is available and is the encoded integer array (0, 1, 2, ...)\n",
        "\n",
        "# 1. Calculate class weights for imbalance correction\n",
        "class_counts = Counter(y_train)\n",
        "total_samples = len(y_train)\n",
        "num_classes = len(class_counts)\n",
        "class_weights = {}\n",
        "for cls, count in class_counts.items():\n",
        "    class_weights[cls] = total_samples / (count * num_classes)\n",
        "\n",
        "# --- 1. Model Definition Function (Adapted for Conv1D) ---\n",
        "def create_conv1d_model(conv_filters, kernel_size, dropout_rate, l2_penalty, input_shape, num_classes):\n",
        "    \"\"\"Creates a regularized Conv1D model with customizable hyperparameters.\"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    # Layer 1: Conv1D with L2 regularization\n",
        "    model.add(Conv1D(\n",
        "        filters=conv_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        activation='relu',\n",
        "        input_shape=input_shape, # Uses input_shape derived from X_functional_3D\n",
        "        kernel_regularizer=l2(l2_penalty)\n",
        "    ))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    \n",
        "    # Global Pooling (Converts sequence output to fixed-length vector)\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "\n",
        "    # Output Layer (Dense layer, uses L2 regularization)\n",
        "    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=l2(l2_penalty)))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001), \n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# --- 2. Setup Search Space (Adapted for Conv1D) ---\n",
        "input_shape = X_functional_3D.shape[1:] \n",
        "num_classes = len(np.unique(y_train)) \n",
        "\n",
        "param_grid = {\n",
        "    'conv_filters': [64, 96, 128],\n",
        "    'kernel_size': [3, 5, 7, 9], # Try larger kernels\n",
        "    'dropout_rate': [0.2, 0.3, 0.4, 0.5],\n",
        "    'l2_penalty': [1e-4, 1e-5],\n",
        "    'batch_size': [16, 32],\n",
        "    'learning_rate': [1e-3, 5e-4, 1e-4] # <-- ADD THIS\n",
        "}\n",
        "\n",
        "N_TRIALS = 50 # Number of random hyperparameter combinations to test\n",
        "N_SPLITS = 5 # 5-Fold Cross-Validation\n",
        "\n",
        "# --- 3. Cross-Validation (CV) Random Search ---\n",
        "best_avg_f1 = -1\n",
        "best_params = {}\n",
        "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
        "\n",
        "print(f\"Starting Random Search CV (Conv1D) with {N_TRIALS} trials and {N_SPLITS} folds...\")\n",
        "\n",
        "for i in range(N_TRIALS):\n",
        "    # Select random parameters for this trial\n",
        "    params = {\n",
        "        'conv_filters': random.choice(param_grid['conv_filters']),\n",
        "        'kernel_size': random.choice(param_grid['kernel_size']),\n",
        "        'dropout_rate': random.choice(param_grid['dropout_rate']),\n",
        "        'l2_penalty': random.choice(param_grid['l2_penalty']),\n",
        "        'batch_size': random.choice(param_grid['batch_size'])\n",
        "    }\n",
        "    \n",
        "    fold_f1_scores = []\n",
        "    \n",
        "    # Define Callbacks for robust training within the fold\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0)\n",
        "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=0)\n",
        "\n",
        "    print(f\"\\n--- Trial {i+1}/{N_TRIALS}. Params: {params} ---\")\n",
        "\n",
        "    # --- 4. K-Fold Training and Evaluation ---\n",
        "    for fold_n, (train_index, val_index) in enumerate(skf.split(X_functional_3D, y_train)):\n",
        "        \n",
        "        # Split Data and Prepare OHE labels for Keras\n",
        "        X_fold_train = X_functional_3D[train_index]\n",
        "        X_fold_val = X_functional_3D[val_index]\n",
        "        y_fold_train_enc = to_categorical(y_train[train_index], num_classes=num_classes)\n",
        "        \n",
        "        # Prepare parameters for model creation (excluding batch_size)\n",
        "        model_creation_params = {k: v for k, v in params.items() if k != 'batch_size'}\n",
        "        \n",
        "        # 1. Create Model (Using the new Conv1D function)\n",
        "        model_trial = create_conv1d_model(\n",
        "            input_shape=input_shape, num_classes=num_classes, **model_creation_params\n",
        "        )\n",
        "        \n",
        "        # 2. Train Model (Applying class_weight for imbalance)\n",
        "        model_trial.fit(\n",
        "            X_fold_train, y_fold_train_enc,\n",
        "            validation_data=(X_fold_val, to_categorical(y_train[val_index], num_classes=num_classes)),\n",
        "            epochs=100, \n",
        "            batch_size=params['batch_size'], \n",
        "            callbacks=[early_stopping, lr_scheduler],\n",
        "            class_weight=class_weights, # Imbalance correction applied!\n",
        "            verbose=0 \n",
        "        )\n",
        "        \n",
        "        # 3. Predict and Calculate F1 Score\n",
        "        raw_predictions = model_trial.predict(X_fold_val, verbose=0)\n",
        "        y_pred_encoded = np.argmax(raw_predictions, axis=1)\n",
        "        \n",
        "        # Calculate Macro F1 Score\n",
        "        f1 = f1_score(y_train[val_index], y_pred_encoded, average='macro')\n",
        "        fold_f1_scores.append(f1)\n",
        "        \n",
        "        print(f\"  Fold {fold_n+1} F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # --- 5. Calculate Average Score ---\n",
        "    avg_f1 = np.mean(fold_f1_scores)\n",
        "    print(f\"  --> Average F1 Score: {avg_f1:.4f}\")\n",
        "    \n",
        "    # --- 6. Track Best Parameters ---\n",
        "    if avg_f1 > best_avg_f1:\n",
        "        best_avg_f1 = avg_f1\n",
        "        best_params = params\n",
        "\n",
        "# --- 7. Final Output ---\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"🏆 Conv1D CV Random Search Complete. Best Average F1 Score: {best_avg_f1:.4f}\")\n",
        "print(f\"✨ Best Parameters Found: {best_params}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting final training with best params: {'conv_filters': 96, 'kernel_size': 5, 'dropout_rate': 0.3, 'l2_penalty': 1e-05, 'batch_size': 32}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Leon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.7700 - loss: 0.7392\n",
            "Epoch 2/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7731 - loss: 0.6602\n",
            "Epoch 3/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7806 - loss: 0.6364\n",
            "Epoch 4/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7897 - loss: 0.6125\n",
            "Epoch 5/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7927 - loss: 0.5990\n",
            "Epoch 6/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7958 - loss: 0.5948\n",
            "Epoch 7/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8033 - loss: 0.5663\n",
            "Epoch 8/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8018 - loss: 0.5567\n",
            "Epoch 9/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8064 - loss: 0.5470\n",
            "Epoch 10/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8079 - loss: 0.5351\n",
            "Epoch 11/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8094 - loss: 0.5153\n",
            "Epoch 12/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8124 - loss: 0.4964\n",
            "Epoch 13/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8139 - loss: 0.4993\n",
            "Epoch 14/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8230 - loss: 0.4720\n",
            "Epoch 15/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8200 - loss: 0.4649\n",
            "Epoch 16/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8336 - loss: 0.4567\n",
            "Epoch 17/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8306 - loss: 0.4464\n",
            "Epoch 18/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8381 - loss: 0.4351\n",
            "Epoch 19/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8381 - loss: 0.4331\n",
            "Epoch 20/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8548 - loss: 0.4158\n",
            "Epoch 21/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8578 - loss: 0.3978\n",
            "Epoch 22/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8608 - loss: 0.3900\n",
            "Epoch 23/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8744 - loss: 0.3862\n",
            "Epoch 24/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8563 - loss: 0.3972\n",
            "Epoch 25/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8714 - loss: 0.3833\n",
            "Epoch 26/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8744 - loss: 0.3800\n",
            "Epoch 27/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8744 - loss: 0.3621\n",
            "Epoch 28/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8790 - loss: 0.3615\n",
            "Epoch 29/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8729 - loss: 0.3671\n",
            "Epoch 30/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8699 - loss: 0.3558\n",
            "Epoch 31/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8835 - loss: 0.3470\n",
            "Epoch 32/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8623 - loss: 0.3667\n",
            "Epoch 33/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8759 - loss: 0.3562\n",
            "Epoch 34/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8956 - loss: 0.3273\n",
            "Epoch 35/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9062 - loss: 0.3214\n",
            "Epoch 36/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8880 - loss: 0.3343\n",
            "Epoch 37/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8805 - loss: 0.3412\n",
            "Epoch 38/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8956 - loss: 0.3224\n",
            "Epoch 39/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8865 - loss: 0.3076\n",
            "Epoch 40/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8926 - loss: 0.3080\n",
            "Epoch 41/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8941 - loss: 0.3057\n",
            "Epoch 42/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8911 - loss: 0.2968\n",
            "Epoch 43/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8986 - loss: 0.2933\n",
            "Epoch 44/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9032 - loss: 0.2924\n",
            "Epoch 45/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9002 - loss: 0.3050\n",
            "Epoch 46/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8896 - loss: 0.3071\n",
            "Epoch 47/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8926 - loss: 0.3158\n",
            "Epoch 48/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8911 - loss: 0.2996\n",
            "Epoch 49/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9017 - loss: 0.2811\n",
            "Epoch 50/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9017 - loss: 0.2862\n",
            "Epoch 51/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8880 - loss: 0.3095\n",
            "Epoch 52/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9077 - loss: 0.2748\n",
            "Epoch 53/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9092 - loss: 0.2701\n",
            "Epoch 54/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9123 - loss: 0.2641\n",
            "Epoch 55/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9077 - loss: 0.2678\n",
            "Epoch 56/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9107 - loss: 0.2624\n",
            "Epoch 57/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9153 - loss: 0.2619\n",
            "Epoch 58/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9092 - loss: 0.2596\n",
            "Epoch 59/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9153 - loss: 0.2523\n",
            "Epoch 60/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9153 - loss: 0.2479\n",
            "Epoch 61/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9183 - loss: 0.2516\n",
            "Epoch 62/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9138 - loss: 0.2480\n",
            "Epoch 63/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9198 - loss: 0.2422\n",
            "Epoch 64/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9183 - loss: 0.2500\n",
            "Epoch 65/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9183 - loss: 0.2440\n",
            "Epoch 66/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9198 - loss: 0.2354\n",
            "Epoch 67/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9183 - loss: 0.2307\n",
            "Epoch 68/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9153 - loss: 0.2398\n",
            "Epoch 69/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9213 - loss: 0.2393\n",
            "Epoch 70/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9304 - loss: 0.2275\n",
            "Epoch 71/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9259 - loss: 0.2262\n",
            "Epoch 72/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9304 - loss: 0.2255\n",
            "Epoch 73/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9107 - loss: 0.2429\n",
            "Epoch 74/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9198 - loss: 0.2193\n",
            "Epoch 75/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9274 - loss: 0.2191\n",
            "Epoch 76/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9228 - loss: 0.2197\n",
            "Epoch 77/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9244 - loss: 0.2139\n",
            "Epoch 78/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9183 - loss: 0.2212\n",
            "Epoch 79/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9289 - loss: 0.2132\n",
            "Epoch 80/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9334 - loss: 0.2142\n",
            "Epoch 81/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9244 - loss: 0.2217\n",
            "Epoch 82/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9304 - loss: 0.2117\n",
            "Epoch 83/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9289 - loss: 0.2175\n",
            "Epoch 84/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9198 - loss: 0.2431\n",
            "Epoch 85/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9349 - loss: 0.2057\n",
            "Epoch 86/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9365 - loss: 0.2003\n",
            "Epoch 87/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9259 - loss: 0.2117\n",
            "Epoch 88/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9334 - loss: 0.2020\n",
            "Epoch 89/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9228 - loss: 0.2004\n",
            "Epoch 90/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9395 - loss: 0.1926\n",
            "Epoch 91/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9319 - loss: 0.2067\n",
            "Epoch 92/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9410 - loss: 0.1901\n",
            "Epoch 93/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9380 - loss: 0.1911\n",
            "Epoch 94/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9380 - loss: 0.1969\n",
            "Epoch 95/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9349 - loss: 0.1857\n",
            "Epoch 96/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9319 - loss: 0.1888\n",
            "Epoch 97/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9395 - loss: 0.1932\n",
            "Epoch 98/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9349 - loss: 0.2179\n",
            "Epoch 99/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9365 - loss: 0.1897\n",
            "Epoch 100/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9274 - loss: 0.1921\n",
            "Restoring model weights from the end of the best epoch: 95.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x2751bf7f350>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# --- I. Model Setup (Reusable Function for CONV1D) ---\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import pandas as pd # Ensure pandas is imported if using df_scalars_test later\n",
        "\n",
        "# NOTE: Parameters change from lstm_units to conv_filters and kernel_size\n",
        "def create_conv1d_model(conv_filters, kernel_size, dropout_rate, l2_penalty, input_shape, num_classes):\n",
        "    \"\"\"Creates a regularized Conv1D model with customizable hyperparameters.\"\"\"\n",
        "    model = Sequential()\n",
        "    \n",
        "    # Conv1D Layer with L2 regularization\n",
        "    model.add(Conv1D(\n",
        "        filters=conv_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        activation='relu',\n",
        "        input_shape=input_shape,\n",
        "        kernel_regularizer=l2(l2_penalty)\n",
        "    ))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    \n",
        "    # Global Pooling (Replaces LSTM's sequence-to-vector output)\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    \n",
        "    # Output Layer\n",
        "    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=l2(l2_penalty)))\n",
        "    \n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# --- II. Final Model Training (Adapted for CONV1D) ---\n",
        "\n",
        "# 1. PLACE YOUR BEST PARAMS HERE (Found during Conv1D CV Search)\n",
        "# NOTE: Replace these placeholder values with your actual best results!\n",
        "best_params = {\n",
        "    'conv_filters': 96,\n",
        "    'kernel_size': 5,\n",
        "    'dropout_rate': 0.3,\n",
        "    'l2_penalty': 1e-5,\n",
        "    'batch_size': 32\n",
        "}\n",
        "\n",
        "# Variables available from earlier cells:\n",
        "input_shape = X_functional_3D.shape[1:] \n",
        "num_classes = len(np.unique(y_train)) \n",
        "X_train_full = X_functional_3D\n",
        "y_train_full_proc = to_categorical(y_train, num_classes=num_classes)\n",
        "\n",
        "# 2. Instantiate the final model\n",
        "# Extract only the parameters required by create_conv1d_model\n",
        "required_params = ['conv_filters', 'kernel_size', 'dropout_rate', 'l2_penalty']\n",
        "final_model_creation_params = {k: v for k, v in best_params.items() if k in required_params}\n",
        "\n",
        "# Use the new Conv1D function\n",
        "final_model = create_conv1d_model(\n",
        "    input_shape=input_shape, num_classes=num_classes, **final_model_creation_params\n",
        ")\n",
        "\n",
        "# 3. Train on the FULL training set\n",
        "final_early_stopping = EarlyStopping(\n",
        "    monitor='loss', \n",
        "    patience=10, \n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(f\"Starting final training with best params: {best_params}\")\n",
        "\n",
        "final_model.fit(\n",
        "    X_train_full, \n",
        "    y_train_full_proc,\n",
        "    epochs=100, # Max epochs, relying on EarlyStopping\n",
        "    batch_size=best_params['batch_size'],\n",
        "    callbacks=[final_early_stopping],\n",
        "    # ADD CLASS WEIGHTS HERE IF YOU CALCULATED THEM: class_weight=class_weights,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test DATASET - Submission Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Scaled Test Scalars shape: (1324, 7)\n"
          ]
        }
      ],
      "source": [
        "# --- A. Extract and Clean Scalar Data ---\n",
        "\n",
        "# Define scalar columns (must match the training definition)\n",
        "scalar_cols = ['sample_index', 'pain_survey_1', 'pain_survey_2', 'pain_survey_3', 'pain_survey_4', \n",
        "               'n_legs', 'n_hands', 'n_eyes']\n",
        "\n",
        "# Extract the unique rows for each pirate\n",
        "df_scalars_test = df_test[scalar_cols].drop_duplicates(subset=['sample_index']).sort_values(by='sample_index')\n",
        "\n",
        "# Define the mapping for count-based strings (must match the training definition)\n",
        "count_mapping = {\n",
        "    'one': 1,\n",
        "    'two': 2,\n",
        "    'three': 3,\n",
        "    'four': 4,\n",
        "}\n",
        "\n",
        "# Apply mapping to the relevant columns\n",
        "for col in ['n_legs', 'n_hands', 'n_eyes']:\n",
        "    df_scalars_test[col] = df_scalars_test[col].map(count_mapping).fillna(0).astype(int) \n",
        "\n",
        "# Drop the index column before scaling\n",
        "X_scalars_raw_test = df_scalars_test.drop(columns=['sample_index']).values\n",
        "\n",
        "# Apply Standard Scaling using the *TRAINING* scaler\n",
        "# scaler was defined and fit earlier in your provided code\n",
        "X_scalars_scaled_test = scaler.transform(X_scalars_raw_test)\n",
        "\n",
        "print(f\"✅ Scaled Test Scalars shape: {X_scalars_scaled_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3D Functional Test Array X_functional_3D_test shape: (1324, 160, 31)\n",
            "✅ Functional Test Data Object fd_test is now defined.\n",
            "   Samples (Pirates): 1324\n"
          ]
        }
      ],
      "source": [
        "# --- B. Create Functional Data Grid (FDataGrid) ---\n",
        "\n",
        "# Define functional columns (must match the training definition)\n",
        "functional_cols = [col for col in df_test.columns if col.startswith('joint_')]\n",
        "\n",
        "# 1. Sort the DataFrame\n",
        "df_test_sorted = df_test.sort_values(by=['sample_index', 'time'])\n",
        "\n",
        "# 2. Extract the functional domain (time vector)\n",
        "# t was defined earlier in your provided code\n",
        "# n_time_points was defined earlier in your provided code\n",
        "\n",
        "# 3. Extract the functional values and reshape\n",
        "X_functional_test = df_test_sorted[functional_cols].values\n",
        "\n",
        "# Reshape to a 3D array: (n_pirates, n_time_points, n_functions)\n",
        "n_pirates_test = df_test['sample_index'].nunique()\n",
        "# n_time_points and n_functions are the same as training\n",
        "\n",
        "X_functional_3D_test = X_functional_test.reshape(n_pirates_test, n_time_points, n_functions)\n",
        "\n",
        "print(f\"3D Functional Test Array X_functional_3D_test shape: {X_functional_3D_test.shape}\")\n",
        "\n",
        "# Create the Functional Data Object\n",
        "fd_test = FDataGrid(\n",
        "    data_matrix=X_functional_3D_test,\n",
        "    grid_points=t # Use the same time vector t\n",
        ")\n",
        "\n",
        "print(f\"✅ Functional Test Data Object fd_test is now defined.\")\n",
        "print(f\"   Samples (Pirates): {fd_test.n_samples}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Test FPCA Score Matrix shape: (1324, 93)\n"
          ]
        }
      ],
      "source": [
        "# --- C. Apply FPCA to Functional Data ---\n",
        "\n",
        "# Split the test FDataGrid into separate joints\n",
        "list_of_fd_grids_test = [fd_test.coordinates[i] for i in range(fd_test.dim_codomain)]\n",
        "    \n",
        "# n_components_per_joint and basis are defined in the training code\n",
        "\n",
        "all_fpc_scores_test = []\n",
        "\n",
        "# NOTE: We must re-instantiate and re-fit FPCA for each joint to maintain \n",
        "# the individual component basis for each joint, as done in the training data.\n",
        "\n",
        "for i, fd_joint_test in enumerate(list_of_fd_grids_test):\n",
        "    # Re-instantiate the FPCA object for the current joint using the same basis/n_components\n",
        "    fpca_i = FPCA(n_components=n_components_per_joint, components_basis=basis)\n",
        "    \n",
        "    # Fit the FPCA to the *TRAINING* joint data (list_of_fd_grids[i])\n",
        "    # list_of_fd_grids was defined in the training code\n",
        "    fpca_i.fit(list_of_fd_grids[i]) \n",
        "    \n",
        "    # Transform the TEST joint data\n",
        "    scores_i_test = fpca_i.transform(fd_joint_test)\n",
        "    all_fpc_scores_test.append(scores_i_test)\n",
        "    \n",
        "# Concatenate all scores horizontally\n",
        "X_fpc_scores_concatenated_test = np.hstack(all_fpc_scores_test)\n",
        "\n",
        "print(f\"Total Test FPCA Score Matrix shape: {X_fpc_scores_concatenated_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Combined Feature Matrix X_combined_test shape: (1324, 100)\n"
          ]
        }
      ],
      "source": [
        "# --- D. Combine Features ---\n",
        "\n",
        "# Combine the FPCA scores and the scaled scalar features\n",
        "X_combined_test = np.hstack([X_fpc_scores_concatenated_test, X_scalars_scaled_test])\n",
        "\n",
        "print(f\"Final Combined Feature Matrix X_combined_test shape: {X_combined_test.shape}\")\n",
        "# Expected shape: (n_pirates_test, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "✅ Generated 1324 string labels.\n",
            "Example predictions (encoded): [2 2 2 2 2]\n",
            "Example predictions (decoded): ['no_pain' 'no_pain' 'no_pain' 'no_pain' 'no_pain']\n",
            "\n",
            "✅ Submission file 'submission_conv1D_CV.csv' created successfully.\n",
            "Format check (first 5 rows):\n",
            "   sample_index    label\n",
            "0             0  no_pain\n",
            "1             1  no_pain\n",
            "2             2  no_pain\n",
            "3             3  no_pain\n",
            "4             4  no_pain\n"
          ]
        }
      ],
      "source": [
        "# 1. Generate Raw Predictions\n",
        "# Use the trained model_finetuned and the 3D functional test data\n",
        "raw_predictions = final_model.predict(X_functional_3D_test)\n",
        "\n",
        "# 2. Convert One-Hot Encoded Predictions to Integer Labels\n",
        "# Since the model_finetuned was trained with to_categorical (OHE), we use argmax\n",
        "y_pred_encoded = np.argmax(raw_predictions, axis=1)\n",
        "\n",
        "# 3. Inverse Transform to Original String Labels\n",
        "# label_encoder was fitted on your training labels (e.g., 'no_pain', 'low_pain')\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred_encoded)\n",
        "\n",
        "print(f\"✅ Generated {len(y_pred_labels)} string labels.\")\n",
        "print(f\"Example predictions (encoded): {y_pred_encoded[:5]}\")\n",
        "print(f\"Example predictions (decoded): {y_pred_labels[:5]}\")\n",
        "\n",
        "# 4. Create the Submission DataFrame\n",
        "# df_scalars_test contains the correct, sorted 'sample_index' for the test set\n",
        "sample_indices_test = df_scalars_test['sample_index'].values\n",
        "\n",
        "df_submission = pd.DataFrame({\n",
        "    'sample_index': sample_indices_test,\n",
        "    'label': y_pred_labels\n",
        "})\n",
        "\n",
        "# 5. Save the DataFrame to the required CSV format\n",
        "submission_filename = 'submission_conv1D_CV.csv'\n",
        "df_submission.to_csv(submission_filename, index=False)\n",
        "\n",
        "print(f\"\\n✅ Submission file '{submission_filename}' created successfully.\")\n",
        "print(\"Format check (first 5 rows):\")\n",
        "print(df_submission.head())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
